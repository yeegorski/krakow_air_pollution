{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all libraries needed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# create the special class that to be used to predict on new data\n",
    "class air_pollution_model():\n",
    "    \n",
    "    # class constructor\n",
    "    def __init__(self,model_file):\n",
    "        # read the saved 'model' file\n",
    "        with open('model','rb') as model_file:\n",
    "            self.reg = pickle.load(model_file)\n",
    "            self.data = None\n",
    "    \n",
    "    # take a data file and preprocess it\n",
    "    def load_and_clean_data(self, data_file):\n",
    "        \n",
    "        # import the data\n",
    "        df = pd.read_csv(data_file)\n",
    "        # store the data in a new variable for later use\n",
    "        self.df_with_predictions = df.copy()\n",
    "        \n",
    "        # turn wind direction into dummy variables\n",
    "        def wind_direction(direction):\n",
    "            if direction > 45 and direction <= 135:\n",
    "                return 'east_wind'\n",
    "            elif direction > 135 and direction <= 225:\n",
    "                return 'south_wind'\n",
    "            elif direction > 225 and direction <= 315:\n",
    "                return 'west_wind'\n",
    "            else:\n",
    "                return 'north_wind'\n",
    "            \n",
    "        df['windBearing'] = df['windBearing'].apply(wind_direction)\n",
    "        wind_bearing_columns = pd.DataFrame(columns = ['east_wind','north_wind','west_wind','south_wind'])\n",
    "        wind_bearing_columns[pd.get_dummies(df['windBearing']).columns] = pd.get_dummies(df['windBearing'])\n",
    "        wind_bearing_columns.fillna(0, inplace = True)\n",
    "        wind_bearing_columns.drop(['north_wind'],axis=1,inplace = True)\n",
    "        \n",
    "        # concatenate column values\n",
    "        df = pd.concat([df,wind_bearing_columns], axis=1)\n",
    "        # drop wind bearing feature\n",
    "        df.drop(['windBearing'], axis = 1, inplace = True)\n",
    "        \n",
    "        # change the unit of speed from km/h to m/s\n",
    "        df['windSpeed'] = df['windSpeed']/3.6\n",
    "        \n",
    "        # convert dates to datetime format\n",
    "        df['time'] = pd.to_datetime(df['time'],format = '%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        # create new feature month\n",
    "        df['month'] = df['time'].apply(lambda time: time.month)\n",
    "\n",
    "        # create new feature hour\n",
    "        df['hour'] = df['time'].apply(lambda time: time.hour)\n",
    "\n",
    "        # create new feature weekday\n",
    "        df['weekday'] = df['time'].apply(lambda time: time.weekday())\n",
    "        \n",
    "        # create dummy variables from month (by seasons), hour (by part of the day), and weekday (weekend or not)\n",
    "        def month_map(month):\n",
    "            if month in [12,1,2]:\n",
    "                return 'winter'\n",
    "            elif month in [3,4,5]:\n",
    "                return 'spring'\n",
    "            elif month in [6,7,8]:\n",
    "                return 'summer'\n",
    "            else:\n",
    "                return 'fall'\n",
    "\n",
    "        def hour_map(hour):\n",
    "            if hour in range(0,6):\n",
    "                return 'night'\n",
    "            elif hour in range(6,12):\n",
    "                return 'morning'\n",
    "            elif hour in range(12,18):\n",
    "                return 'afternoon'\n",
    "            else:\n",
    "                return 'evening'\n",
    "\n",
    "        def weekday_map(weekday):\n",
    "            if weekday in range(0,5):\n",
    "                return 'workday'\n",
    "            else:\n",
    "                return 'weekend'\n",
    "\n",
    "        df['month'] = df_time['month'].apply(month_map)\n",
    "        df['hour'] = df_time['hour'].apply(hour_map)\n",
    "        df['weekday'] = df_time['weekday'].apply(weekday_map)\n",
    "        \n",
    "        season_columns = pd.get_dummies(df_time_dummies['month'], drop_first = True)\n",
    "        daypart_columns = pd.get_dummies(df_time_dummies['hour'], drop_first = True)\n",
    "        weekend_columns = pd.get_dummies(df_time_dummies['weekday'], drop_first = True)\n",
    "        \n",
    "        # concatenate column values\n",
    "        df = pd.concat([df,season_columns,daypart_columns,weekend_columns], axis = 1)\n",
    "        \n",
    "        # drop time, month, hour, weekday columns\n",
    "        df = df.drop(['time','month','hour','weekday'], axis = 1)\n",
    "        \n",
    "        df = df[['temperature', 'humidity', 'pressure', 'windSpeed', 'visibility', 'east_wind', 'south_wind', 'west_wind',\n",
    "                 'spring', 'summer', 'winter', 'evening', 'morning', 'night', 'workday']]\n",
    "        \n",
    "        # create a variable to call the preprocessed data\n",
    "        self.data = df.copy()\n",
    "        \n",
    "    \n",
    "    # predict the PM2 and the pollution level and\n",
    "    # add columns with these values at the end of the new data\n",
    "    def predicted_outputs(self):\n",
    "        \n",
    "        # divide data on pollution levels\n",
    "        def pol_levels(x):\n",
    "            if x <= 12:\n",
    "                return 'healthy'\n",
    "            elif x > 12 and x <=35.4:\n",
    "                return 'moderate'\n",
    "            elif x > 35.4 and x <=55.4:\n",
    "                return 'unhealthy for sensitive groups'\n",
    "            elif x > 55.4 and x <=150.4:\n",
    "                return 'unhealthy'\n",
    "            else:\n",
    "                return 'hazardous' \n",
    "                \n",
    "        if (self.data is not None):\n",
    "            self.data['PM2'] = self.reg.predict(self.data)\n",
    "            self.data['Pollution Level'] = self.data['PM2'].apply(pol_levels)\n",
    "            return self.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
